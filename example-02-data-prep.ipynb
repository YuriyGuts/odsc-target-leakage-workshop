{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Leakage in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Â© Yuriy Guts, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 02: Data Preparation Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will explore how preprocessing the dataset before partitioning can introduce minor leakage about the test features into the training pipeline.\n",
    "As a result, our model will have slightly better scores compared to the more robust approach where we derive preprocessing parameters on the training subset, and then use them to transform the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This is a toy example on a rather small dataset so the impact won't be large but visible enough to illustrate the point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler, Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read the [Titanic](https://www.kaggle.com/c/titanic/data) dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic-train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using KNN, so let's one-hot encode the two categorical variables: sex and the port of departure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['IsFemale'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['IsAgeMissing'] = df['Age'].isnull()\n",
    "df[['EmbarkedC', 'EmbarkedQ', 'EmbarkedS']] = pd.get_dummies(df['Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's leave only the simple features that are likely to carry the most signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_X = df[['Pclass', 'IsFemale', 'Age', 'IsAgeMissing', 'SibSp', 'Parch', 'Fare', 'EmbarkedC', 'EmbarkedQ', 'EmbarkedS']].copy()\n",
    "df_y = df['Survived'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MISTAKE INCOMING!** Now we will transform the entire dataset, before partitioning it into train and test. This is likely to cause leakage if the features drift significantly across the training and evaluation folds. We do not actually know the distribution of the test features at prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_imputer = Imputer(missing_values='NaN', strategy='mean')\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X['Age'] = mean_imputer.fit_transform(df_X[['Age']])\n",
    "df_X[['Age', 'Fare']] = scaler.fit_transform(df_X[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29.69911765]\n"
     ]
    }
   ],
   "source": [
    "print(mean_imputer.statistics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 29.69911765  32.20420797]\n",
      "[ 12.99471687  49.66553444]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only now will we partition and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (623, 10)\n",
      "X_test:  (268, 10)\n",
      "y_train: (623,)\n",
      "y_test:  (268,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train:', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "print('y_train:', y_train.shape)\n",
    "print('y_test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict_proba(X_test)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss_before = log_loss(y_test, y_test_pred)\n",
    "auc_before = roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test LogLoss: 4.03039167749\n",
      "Test AUC:     0.755666208791\n"
     ]
    }
   ],
   "source": [
    "print('Test LogLoss:', log_loss_before)\n",
    "print('Test AUC:    ', auc_before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.045685896518762134\n",
      "0.10620266242980987\n"
     ]
    }
   ],
   "source": [
    "print(X_train['Age'].mean())\n",
    "print(X_test['Age'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat our initial dataset preparation (missing indicator variable, one-hot encoding, feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/titanic-train.csv')\n",
    "df['IsFemale'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['IsAgeMissing'] = df['Age'].isnull()\n",
    "df[['EmbarkedC', 'EmbarkedQ', 'EmbarkedS']] = pd.get_dummies(df['Embarked'])\n",
    "df_X = df[['Pclass', 'IsFemale', 'Age', 'IsAgeMissing', 'SibSp', 'Parch', 'Fare', 'EmbarkedC', 'EmbarkedQ', 'EmbarkedS']].copy()\n",
    "df_y = df['Survived'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we'll partition first, then figure out the preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.copy()\n",
    "X_test = X_test.copy()\n",
    "y_train = y_train.copy()\n",
    "y_test = y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn imputation parameters only on the training set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_imputer = Imputer(missing_values='NaN', strategy='mean')\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['Age'] = mean_imputer.fit_transform(X_train[['Age']])\n",
    "X_train[['Age', 'Fare']] = scaler.fit_transform(X_train[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 28.95791583]\n"
     ]
    }
   ],
   "source": [
    "print(mean_imputer.statistics_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 28.95791583  31.82662424]\n",
      "[ 12.86442653  45.07671825]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.scale_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and use them to **transform** the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test['Age'] = mean_imputer.transform(X_test[['Age']])\n",
    "X_test[['Age', 'Fare']] = scaler.transform(X_test[['Age', 'Fare']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = model.predict_proba(X_test)[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss_after = log_loss(y_test, y_test_pred)\n",
    "auc_after = roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test LogLoss: 4.03341753651\n",
      "Test AUC:     0.753147893773\n"
     ]
    }
   ],
   "source": [
    "print('Test LogLoss:', log_loss_after)\n",
    "print('Test AUC:    ', auc_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Impact of Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogLoss difference: 0.00302585901573\n",
      "AUC difference:     -0.00251831501832\n"
     ]
    }
   ],
   "source": [
    "print('LogLoss difference:', log_loss_after - log_loss_before)\n",
    "print('AUC difference:    ', auc_after - auc_before)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
